---
title: 'Project 1'
author: "Lauren Murray lcm2624"
date: '2021-05-09'
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    toc: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align = "center", warning = F, message = F,
tidy=TRUE, tidy.opts=list(width.cutoff=60), R.options=list(max.print=100))
```


<P style="page-break-before: always">
\newpage

### Introduction

- I have combined 4 data sets for this project. The independent variables that are joined, common for all data sets, are year and country. The dependent variables I am assessing are country code, population, deaths due to terrorist attacks, banking crisis incidence, and number of vehicles produced in a year. I chose these data sets to analyze the correlation between all of these variables over time and in different countries. The countries that I chose to study here are France, Argentina, Australia, Belgium, Brazil, Canada, China, Germany, India, and Spain. I am looking at statistics for these countries only in the years 1970, 1980, 1990, 2000, and 2010. These data sets came from https://vincentarelbundock.github.io/Rdatasets/datasets.html
- With the COVID-19 pandemic occurring this year I have been made aware more than ever of how one event can cause a ripple effect that alters daily life in ways that are not always expected. Along that train of thought, during my research trying to find data sets to join I came upon these data sets and wondered if a banking crisis would decrease car production; or if the increase in terrorist violence could be the associated with a change in population; and so on and so forth. I expect that the larger the population is for a given observation that there will be more deaths due to terrorist attacks and more vehicles produced in a year. I also expect that the occurrence of a banking crisis will have a negative effect on number of cars produced and a positive correlation with number of deaths caused by terrorist attacks. 

### Tidying: Rearranging Wide/Long
```{R}
library(tidyverse)
library(dplyr)
library(readr)
countrypops <- read_csv("countrypops.csv")
countrypopulation<- countrypops %>% 
  arrange(year) %>% 
  filter(country_name=="India"| country_name== "Canada"|country_name== "Germany"|country_name=="Argentina"| country_name=="Belgium"| country_name=="Brazil"| country_name=="China"|country_name=="Australia"|country_name=="France"|country_name=="Spain") %>%
  filter(year=="1970"|year=="1980"|year=="1990"|year=="2000"|year=="2010") %>% 
  select(year, country_name,country_code_2, population)%>%
  rename("Country"=country_name, "Country Code"=country_code_2, "Year"=year)
countrypopulation

library(readr)
bankingCrises <- read_csv("bankingCrises.csv")
bankingcrisis<- bankingCrises%>%
  arrange(year) %>%
  pivot_longer(c("Algeria","Angola","Argentina", "Australia","Austria", "Belgium", "Bolivia", "Brazil", "Canada", "CentralAfricanRep","Chile", "China", "Colombia","CostaRica", "CoteDIvoire", "Denmark", "DominicanRepublic", "Ecuador", "Egypt","ElSalvador","Finland", "France", "Germany","Ghana","Greece", "Guatemala","Honduras","Hungary","Iceland","India", "Indonesia", "Ireland", "Italy","Japan","Kenya", "Korea", "Malaysia", "Mauritius", "Mexico", "Morocco", "Myanmar", "Netherlands", "NewZealand", "Nicaragua", "Nigeria", "Norway", "Panama", "Paraguay", "Peru","Philippines","Poland", "Portugal", "Romania", "Russia", "Singapore", "SouthAfrica", "Spain", "SriLanka", "Sweden", "Switzerland", "Taiwan", "Thailand", "Tunisia", "Turkey", "UK","Uruguay","US","Venezuela", "Zambia","Zimbabwe"), names_to="Country", values_to="count")%>%
  filter(year=="1970"|year=="1980"|year=="1990"|year=="2000"|year=="2010")%>%
  filter(Country=="India"|Country=="Brazil"|Country=="Canada"|Country=="China"|Country=="Germany" | Country=="Belgium"|Country=="Argentina"|Country=="Australia"|Country=="France"|Country=="Spain")%>% 
  select(Country, year, count)%>% 
  rename("Banking Crises"=count, "Year"=year)
bankingcrisis

library(readr)
mvprod <- read_csv("mvprod.csv")
vehicleProduction<- mvprod %>%
  arrange(year)%>%
  filter(country=="India"|country=="Canada"|country== "Germany"|country=="Brazil"|country=="China"| country=="Belgium"| country=="Argentina"| country=="Australia"| country=="France"|country=="Spain")%>%
  filter(year=="1970"|year=="1980"|year=="1990"|year=="2000"|year=="2010")%>%
  select(year, country, value)%>%
  rename("Cars Produced"=value, "Year"=year, "Country"=country)
vehicleProduction

library(readr)
nkill_byCountryYr <- read_csv("nkill.byCountryYr.csv")
DeathsFromTerrorism<- nkill_byCountryYr%>%
  pivot_longer(c("1970","1971","1972","1973","1974","1975","1976","1977","1978","1979","1980","1981","1982","1983","1984","1985","1986","1987","1988","1989","1990","1991","1992","1993","1994","1995","1996","1997","1998","1999","2000","2001","2002", "2003","2004","2005","2006","2007","2008","2009","2010","2011","2012","2013","2014","2015"), names_to="year", values_to="count") %>%
  arrange(year)%>% 
  rename("country"=X1) %>%
  filter(country=="India"|country=="Canada"|country== "Germany"|country=="Brazil"|country=="China"| country=="Belgium"| country=="Argentina"| country=="Australia"| country=="France"|country=="Spain") %>%
  filter(year=="1970"|year=="1980"|year=="1990"|year=="2000"|year=="2010")%>%
  select(year, country, count)%>%
  mutate(year=as.numeric(year)) %>%
  rename("Year"=year, "Country"=country, "Terrorism Deaths"= count) %>%
  arrange(Year)
DeathsFromTerrorism
```
- Tidying the data was done to allow me to easily join the data sets later on. I had to use pivot_longer on the bankingCrises data set and the nkill_byCountryYr data set in order to turn the countries from a row into a column and to turn the years from a row into a column, respectively. I also used the dplyr functions filter(), select(), and arrange() to organize my data sets so that I could get better understanding for how I wanted to join them and so that I could use the full_join() function later without having to worry about getting rid of extraneous columns when joining.  
    
### Joining/Merging the Data
```{R}
OverallTable<- countrypopulation %>% 
  full_join(vehicleProduction) %>% 
  full_join(bankingcrisis) %>%
  full_join(DeathsFromTerrorism)
OverallTable
```
- I decided to use full_join because it allowed me to combine all of the observations based on both year and country, thus condensing the table and allowing me to add the subsequent columns (variables) alongside for each data set. I already tidied up my individual data sets up prior to joining them so no rows(observations) were lost. This is why I used the filter() function prior so that I could choose which countries I wanted in my overall data set and which years I wanted in my overall data set. I used the select() function prior as well so that I could manually remove all of the unwanted variables. full_join() worked because I did all of this prior organizing.

### Wrangling the Data
```{R}
OverallTable_mutated<- OverallTable%>% 
  mutate('Percent of Population Killed'=(`Terrorism Deaths`/population)*100)%>% 
  arrange(Year)
OverallTable_mutated
```


- In using all 6 core dplyr functions, 2 are shown above and the other 4 were used in the tidying data section. I used mutate() to create a new column in my data set called Percent of Population killed to look deeper into the relationship between terrorism caused deaths and population in a country in a specific year. Then I used arrange() to organize the data set by year from oldest to newest data observations. Filter() was used in tidying my data to keep only the countries and years that I wanted in the data set rather than all of them from the original data sets. Select() was used so that only the variables that I wanted to study stayed present and not other variables like secondary country codes that I didn't want to study. I used summarize() below in order to gather statistics about the different variables in the data set. I used group_by() below as well to categorize the summarize statistics by country to view the data through a slightly different lens, I analyze the results more below. 

```{R}
OverallTable %>% group_by(Country) %>% 
  summarize(mean_population= mean(population,na.rm=T), sd_population=sd(population, na.rm=T), max_population=max(population, na.rm=T), min_population=min(population, na.rm=T), median_population=median(population, na.rm=T))

OverallTable %>% group_by(Country) %>% 
  summarize(mean_cars= mean(`Cars Produced`,na.rm=T), sd_cars=sd(`Cars Produced`, na.rm=T), max_cars=max(`Cars Produced`, na.rm=T), min_cars=min(`Cars Produced`, na.rm=T), median_cars=median(`Cars Produced`, na.rm=T))

OverallTable %>% group_by(Country) %>% 
  summarize(mean_deaths= mean(`Terrorism Deaths` ,na.rm=T), sd_deaths=sd(`Terrorism Deaths`, na.rm=T), max_deaths=max(`Terrorism Deaths`, na.rm=T), min_deaths=min(`Terrorism Deaths`, na.rm=T), median_deaths=median(`Terrorism Deaths`, na.rm=T))

OverallTable %>% group_by(Year) %>% 
  summarize(mean_population= mean(population,na.rm=T), sd_population=sd(population, na.rm=T), max_population=max(population, na.rm=T), min_population=min(population, na.rm=T), median_population=median(population, na.rm=T))
  
OverallTable%>% summarize(mean_deaths=mean(`Terrorism Deaths`, na.rm=T))

OverallTable%>% summarize(mean_cars=mean(`Cars Produced`, na.rm=T))

OverallTable%>% summarize(mean_population=mean(population, na.rm=T))

```
- As I previously stated, the summarize and group_by functions I used above give me more of an understanding for the statistics of my data. When grouped by country China and India had the largest mean populations of 1,107,017,000 people and 880,905,423 people, respectively. China then had also the second highest mean car production per year of 4,230,505 cars, beat only by Germany who produced a mean amount of cars of 4,825,990 cars. India had the highest maximum deaths in a year due to terrorist attacks, 907 deaths. Grouped by year, mean population in countries increases each year from 1970 to 2010.


### Visualizing the Data
```{R}
library(ggplot2)
correlationmat <- OverallTable %>% select_if(is.numeric) %>% cor(use="pair")
tidycorrelations <- correlationmat %>% as.data.frame %>% rownames_to_column("var1") %>%
  pivot_longer(-1,names_to="var2",values_to="correlation")
tidycorrelations
tidycorrelations%>%ggplot(aes(var1, var2,fill=correlation))+
  geom_tile()+
  scale_fill_gradient2(low="red",mid="white",high="blue")+ 
  geom_text(aes(label=round(correlation,2)),color = "black", size = 4)+ 
  theme(axis.text.x = element_text(angle = 90, hjust=1))+ 
  coord_fixed()
```

- This correlation heat map that was produced shows the strength of a linear relationship between two numeric variables. The strongest positive correlation is between population and number of deaths resulting from terrorist attacks, with a correlation of 0.51. The second strongest positive correlation is between the year and the number of cars produced in countries, with a correlation of 0.33. The relationship between population and cars produced is also positive, with a correlation of 0.27. As time passes(year increases) there is a positive correlation between it and all other variables. Banking Crises has a negative correlation with all other varibales except year. 

```{R}
ggplot(OverallTable, aes(x=population, y=`Cars Produced`, fill=Country)) +
  geom_point(aes(color=Country, size=Year)) + 
  scale_size_continuous("Year", range=c(3,1)) + 
  labs(x="Population", y="Number of Cars Produced Per Year", title="Number of Cars Produced Per Year versus Population")
  
```
- This graph shows the relationship between the number of cars produced by a country in a specific year and the population of that country in that specific year. There is a trend that suggest that as time has gone by population and the number of cars produced has tended to increase with the smaller dots being seen more to the right and the top of the graph.By giving each country a different color we are able to see the changes that each country has gone through over time by following their individual dots. China had a very large increase in car production compared to any other country.  

```{R}
ggplot(OverallTable, aes(Country)) + 
  geom_bar(aes(y=`Terrorism Deaths`, fill=`Banking Crises`), colour="black", stat="summary", fun=mean) +
  theme(axis.text.y = element_text(angle=0, hjust=1, colour="blue", size=7)) +
  coord_flip()+
  labs(y="Average Yearly Deaths Due to Terrorism", x="Country", title= "Country versus Average Deaths Due to Terrorism") +
  labs(fill="Banking Crisis Did Not Occur")
```
- In this graph it is very apparent that India has the largest mean deaths due to terrorism. India has also not experienced a banking crisis in the years being studied. The other countries have much lower mean deaths due to terrorism, Spain has the second highest and they have experienced a banking crisis sometime in the years being studied.


### Dimensionality Reduction
```{R}
cluster_data<- OverallTable %>% select(population, `Cars Produced`, `Terrorism Deaths`)
library(cluster)
sil_width<-vector() 
for(i in 2:10){
kms <- kmeans(cluster_data,centers=i) 
sil <- silhouette(kms$cluster,dist(cluster_data)) 
sil_width[i]<-mean(sil[,3]) 
}
ggplot()+geom_line(aes(x=1:10,y=sil_width))+scale_x_continuous(name="k",breaks=1:10)
```

-I decided to use 2 kmeans to analyze my data because of the results of the silhouette width graph which shows the cohesiveness and separation of the clusters. Therefore the higher the silhouette width is the better, so 2 is chosen to be the number of clusters.

```{R}
kmeans2<-cluster_data%>%
  scale %>%
  kmeans(2)
kmeans2
kmeanscluster <- cluster_data %>% mutate(cluster=as.factor(kmeans2$cluster))
kmeanscluster %>% ggplot(aes(population,`Cars Produced`, `Terrorism Deaths`, color=cluster)) + geom_point()
```

- This cluster graph shows a fairly distinct separation between the two clusters although they do seem to be very near in the bottom right corner. There is also a one spot high in the upper corner and that suggests that the data points in the second cluster especially may not be very close together. The first cluster though does have that very concentrated area to the bottom left which suggests it is closer together. There are only 4 observations in cluster 2 which is much fewer than cluster 1 which has 46 observations. This could be because of the one outlier that can be seen in the top right of the graph. This one point would probably have less effect on the clustering if PAM was used(see further down for results of PAM) 

```{R}
library(GGally)
ggpairs(kmeanscluster, columns = 1:3, aes(color=cluster))
```
- This set of graphs allows us to see the correlation between each of the variables with eachother. The highest correlation is the positive correlation that exists between population and number of deaths due to terrorism, 0.505. This means that as population increases so does the number of deaths due to terrorism in a year. There is also a positive correlation between population and cars produced but it it fairly weak, 0.269. Then there is a negative correlation between cars produced and terrorism deaths, -0.034. It is a very weak correlation that suggests that more cars produced is associated with less deaths due to terrorism, again weakly.

```{R}
library(cluster)
pam2<-OverallTable%>% select(population,`Cars Produced`, `Terrorism Deaths`) %>% scale%>% pam(k=2)
pam2
pamcluster<-cluster_data %>% mutate(cluster=as.factor(pam2$clustering))
pamcluster %>% ggplot(aes(population, `Cars Produced`, `Terrorism Deaths`,color=cluster)) + geom_point()
```
```{R}
pamcluster %>% group_by(cluster) %>% summarize_if(is.numeric,mean,na.rm=T)
plot(pam2, which=2)
```
*The PAM(partitioning around medoids) average silhouette width of 0.64 shows us that a reasonable structure has been found meaning a decent goodness of fit. This shows us that in general among my data, certain countries at certain years will form decently correlated clusters based on deaths due to terrorist attacks, population, and car production. These three numeric variables are the numeric variables being analyzed in this PAM test as was done using the select() dplyr function. The graph and the silhouette plot show this reasonable structure visibly. The PAM algorithm is different from the other clustering algorithm because it centers the cluster around medoids which are not as sensitive to outliers like means are. Means are used in the initial clustering graphs and are likely to be less accurate at clustering. Medoids are multidimensional medians and therefore less subject to being thrown off by outliers.*


